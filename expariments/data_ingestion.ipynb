{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning Pipline Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networksecurity.constant import traning_pipline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class TraningPiplineConfig:\n",
    "    def __init__(self) -> None:\n",
    "      self.pipline_name=traning_pipline.PIPELINE_NAME   \n",
    "      self.artifact_name=traning_pipline.ARTIFACT_DIR\n",
    "      self.artifact_dir=os.path.join(self.artifact_name)\n",
    "      \n",
    "class DataIngestionConfig:\n",
    "      def __init__(self,traning_pipline_config:TraningPiplineConfig) -> None:\n",
    "         self.data_ingestion_dir:str=os.path.join(\n",
    "            traning_pipline_config.artifact_dir, traning_pipline.DATA_INGESTION_DIR_NAME ## creating data ingestion dir inside artifacts\n",
    "\t\t\t)\n",
    "         self.feature_store_file_path:str=os.path.join(\n",
    "            traning_pipline_config.artifact_dir, traning_pipline.DATA_INGESTION_FEATURE_STORE_DIR ,traning_pipline.FILE_NAME ## saving raw data in artifact with file name\n",
    "\t\t\t)\n",
    "         self.traning_data_store_path:str=os.path.join(\n",
    "            traning_pipline_config.artifact_dir, traning_pipline.DATA_INGESTION__DIR, traning_pipline.TRAIN_FILE_NAME  ## artifacts folder , ingest folder , train data path\n",
    "\t\t\t)\n",
    "         self.test_data_store_path:str=os.path.join(\n",
    "            traning_pipline_config.artifact_dir,traning_pipline.DATA_INGESTION__DIR, traning_pipline.TEST_FILE_NAME ## artifacts folder , ingest folder , test data path\n",
    "\t\t\t)\n",
    "         self.train_test_split_ratio:float=traning_pipline.DATA_INGESTION_TRAIN_TEST_SPLIT_RATIO\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components Output Artifacts Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class DataIngestionArtifact:\n",
    "    trained_file_path:str\n",
    "    test_file_path:str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networksecurity.logging.logger import logging\n",
    "from networksecurity.exception.exception import CustomException\n",
    "from networksecurity.utils.utills import Data_read_from_db\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from networksecurity.logging.logger import logging\n",
    "from networksecurity.exception.exception import CustomException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "   def __init__(self,data_ingestion_config:DataIngestionConfig) -> None:\n",
    "      self.config = data_ingestion_config\n",
    "      self.url = os.getenv('url')\n",
    "      self.database = os.getenv('db')\n",
    "      self.collection = os.getenv('collection')\n",
    "   def export_data_to_feature_store(self,df:pd.DataFrame) -> pd.DataFrame:\n",
    "      try:\n",
    "         feature_store_dir_path:str=self.config.feature_store_file_path\n",
    "         dir_path=os.path.dirname(feature_store_dir_path)\n",
    "         os.makedirs(dir_path,exist_ok=True)\n",
    "         df.to_csv(feature_store_dir_path,index=False,header=True)\n",
    "         return df\n",
    "      except Exception as e:\n",
    "         logging.info(f'Error in export data {str(e)}')\n",
    "         raise CustomException(e,sys)\n",
    "   def split_data_into_train_test(self,df):\n",
    "      try:\n",
    "         test_data,train_data=train_test_split(\n",
    "            df,test_size=self.config.train_test_split_ratio,random_state=42\n",
    "\t\t\t)\n",
    "         logging.info('Data split into training and testing sets successfully.')\n",
    "         train_dir_path=os.path.dirname(self.config.traning_data_store_path)\n",
    "         os.makedirs(train_dir_path,exist_ok=True)\n",
    "         train_data.to_csv(self.config.traning_data_store_path)\n",
    "         print(train_data.info())\n",
    "         test_dir_path=os.path.dirname(self.config.test_data_store_path)\n",
    "         os.makedirs(test_dir_path,exist_ok=True)\n",
    "         test_data.to_csv(self.config.test_data_store_path)\n",
    "         logging.info(f'Training and test data saved to {self.config.traning_data_store_path} and {self.config.test_data_store_path} respectively.')\n",
    "      except Exception as e:\n",
    "         raise CustomException(e,sys)\n",
    "   def initiate_data_ingestion(self):\n",
    "      try:\n",
    "         df=Data_read_from_db(url=self.url,db=self.database,collection=self.collection)\n",
    "         self.export_data_to_feature_store(df=df)\n",
    "         self.split_data_into_train_test(df=df)\n",
    "         data_ingestion_artifacts=DataIngestionArtifact(\n",
    "            trained_file_path=self.config.traning_data_store_path,test_file_path=self.config.test_data_store_path\n",
    "\t\t\t)\n",
    "         return data_ingestion_artifacts\n",
    "      except Exception as e:\n",
    "         logging.info(f'Error in Data Ingestion: {str(e)}')\n",
    "         raise CustomException(e,sys)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from networksecurity.entity.artifact_entity import DataIngestionArtifact\n",
    "# from networksecurity.entity.config_entity import DataIngestonConfig\n",
    "# from networksecurity.logging.logger import logging\n",
    "# from networksecurity.exception.exception import CustomException\n",
    "# import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   having_IP_Address  URL_Length  Shortining_Service  having_At_Symbol  \\\n",
      "0                 -1           1                   1                 1   \n",
      "1                  1           1                   1                 1   \n",
      "2                  1           0                   1                 1   \n",
      "3                  1           0                   1                 1   \n",
      "4                  1           0                  -1                 1   \n",
      "\n",
      "   double_slash_redirecting  Prefix_Suffix  having_Sub_Domain  SSLfinal_State  \\\n",
      "0                        -1             -1                 -1              -1   \n",
      "1                         1             -1                  0               1   \n",
      "2                         1             -1                 -1              -1   \n",
      "3                         1             -1                 -1              -1   \n",
      "4                         1             -1                  1               1   \n",
      "\n",
      "   Domain_registeration_length  Favicon  ...  popUpWidnow  Iframe  \\\n",
      "0                           -1        1  ...            1       1   \n",
      "1                           -1        1  ...            1       1   \n",
      "2                           -1        1  ...            1       1   \n",
      "3                            1        1  ...            1       1   \n",
      "4                           -1        1  ...           -1       1   \n",
      "\n",
      "   age_of_domain  DNSRecord  web_traffic  Page_Rank  Google_Index  \\\n",
      "0             -1         -1           -1         -1             1   \n",
      "1             -1         -1            0         -1             1   \n",
      "2              1         -1            1         -1             1   \n",
      "3             -1         -1            1         -1             1   \n",
      "4             -1         -1            0         -1             1   \n",
      "\n",
      "   Links_pointing_to_page  Statistical_report  Result  \n",
      "0                       1                  -1      -1  \n",
      "1                       1                   1      -1  \n",
      "2                       0                  -1      -1  \n",
      "3                      -1                   1      -1  \n",
      "4                       1                   1       1  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2875 entries, 10582 to 68\n",
      "Data columns (total 31 columns):\n",
      " #   Column                       Non-Null Count  Dtype\n",
      "---  ------                       --------------  -----\n",
      " 0   having_IP_Address            2875 non-null   int64\n",
      " 1   URL_Length                   2875 non-null   int64\n",
      " 2   Shortining_Service           2875 non-null   int64\n",
      " 3   having_At_Symbol             2875 non-null   int64\n",
      " 4   double_slash_redirecting     2875 non-null   int64\n",
      " 5   Prefix_Suffix                2875 non-null   int64\n",
      " 6   having_Sub_Domain            2875 non-null   int64\n",
      " 7   SSLfinal_State               2875 non-null   int64\n",
      " 8   Domain_registeration_length  2875 non-null   int64\n",
      " 9   Favicon                      2875 non-null   int64\n",
      " 10  port                         2875 non-null   int64\n",
      " 11  HTTPS_token                  2875 non-null   int64\n",
      " 12  Request_URL                  2875 non-null   int64\n",
      " 13  URL_of_Anchor                2875 non-null   int64\n",
      " 14  Links_in_tags                2875 non-null   int64\n",
      " 15  SFH                          2875 non-null   int64\n",
      " 16  Submitting_to_email          2875 non-null   int64\n",
      " 17  Abnormal_URL                 2875 non-null   int64\n",
      " 18  Redirect                     2875 non-null   int64\n",
      " 19  on_mouseover                 2875 non-null   int64\n",
      " 20  RightClick                   2875 non-null   int64\n",
      " 21  popUpWidnow                  2875 non-null   int64\n",
      " 22  Iframe                       2875 non-null   int64\n",
      " 23  age_of_domain                2875 non-null   int64\n",
      " 24  DNSRecord                    2875 non-null   int64\n",
      " 25  web_traffic                  2875 non-null   int64\n",
      " 26  Page_Rank                    2875 non-null   int64\n",
      " 27  Google_Index                 2875 non-null   int64\n",
      " 28  Links_pointing_to_page       2875 non-null   int64\n",
      " 29  Statistical_report           2875 non-null   int64\n",
      " 30  Result                       2875 non-null   int64\n",
      "dtypes: int64(31)\n",
      "memory usage: 718.8 KB\n",
      "None\n"
     ]
    },
    {
     "ename": "CustomException",
     "evalue": "Error occurred python script name [C:\\Users\\www58\\AppData\\Local\\Temp\\ipykernel_7872\\1019428492.py] line number [5] error message [cannot unpack non-iterable DataIngestionArtifact object]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      4\u001b[0m    data_ingestion\u001b[38;5;241m=\u001b[39mDataIngestion(data_ingestion_config\u001b[38;5;241m=\u001b[39mdata_ingestion_config)\n\u001b[1;32m----> 5\u001b[0m    t,te\u001b[38;5;241m=\u001b[39mdata_ingestion\u001b[38;5;241m.\u001b[39minitiate_data_ingestion()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable DataIngestionArtifact object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m    t,te\u001b[38;5;241m=\u001b[39mdata_ingestion\u001b[38;5;241m.\u001b[39minitiate_data_ingestion()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m----> 7\u001b[0m            \u001b[38;5;28;01mraise\u001b[39;00m CustomException(e,sys)\n",
      "\u001b[1;31mCustomException\u001b[0m: Error occurred python script name [C:\\Users\\www58\\AppData\\Local\\Temp\\ipykernel_7872\\1019428492.py] line number [5] error message [cannot unpack non-iterable DataIngestionArtifact object]"
     ]
    }
   ],
   "source": [
    "try:\n",
    "   traning_pipline_config=TraningPiplineConfig()\n",
    "   data_ingestion_config=DataIngestionConfig(traning_pipline_config=traning_pipline_config)\n",
    "   data_ingestion=DataIngestion(data_ingestion_config=data_ingestion_config)\n",
    "   data_ingestion.initiate_data_ingestion()\n",
    "except Exception as e:\n",
    "           raise CustomException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in d:\\mlops\\network security\\ns\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in d:\\mlops\\network security\\ns\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in d:\\mlops\\network security\\ns\\lib\\site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\mlops\\network security\\ns\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\mlops\\network security\\ns\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\mlops\\network security\\ns\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\mlops\\network security\\ns\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\mlops\\network security\\ns\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in d:\\mlops\\network security\\ns\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\mlops\\network security\\ns\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\mlops\\network security\\ns\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\mlops\\network security\\ns\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\mlops\\network security\\ns\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\mlops\\network security\\ns\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df=sns.load_dataset('tips')\n",
    "df=df.select_dtypes(exclude='category')\n",
    "train,test=train_test_split(df,test_size=0.26,random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 180 entries, 122 to 200\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   total_bill  180 non-null    float64\n",
      " 1   tip         180 non-null    float64\n",
      " 2   size        180 non-null    int64  \n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 5.6 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS Test p-value: [0.43641559 0.10972994 0.21902045]\n",
      "[0.12256944 0.17118056 0.14895833]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# Assuming base_data and current_data are two datasets (e.g., pandas Series)\n",
    "ks_stat, p_value = ks_2samp(train, test)\n",
    "print(\"KS Test p-value:\", p_value)\n",
    "print(ks_stat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
