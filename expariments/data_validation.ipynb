{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning Pipline Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networksecurity.constant import traning_pipline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class TraningPiplineConfig:\n",
    "    def __init__(self) -> None:\n",
    "      self.pipline_name=traning_pipline.PIPELINE_NAME   \n",
    "      self.artifact_name=traning_pipline.ARTIFACT_DIR\n",
    "      self.artifact_dir=os.path.join(self.artifact_name)\n",
    "      \n",
    "class DataValidationConfig:\n",
    "    def __init__(self,traning_pipline_config:TraningPiplineConfig) -> None:\n",
    "      self.data_validation_dir:str=os.path.join(\n",
    "      \ttraning_pipline_config.artifact_dir,traning_pipline.DATA_VALIDATION_DIR_NAME ## crating data validaton folder inside artifacts\n",
    "\t\t)\n",
    "      self.valid_dir_name:str=os.path.join(\n",
    "         self.data_validation_dir, traning_pipline.DATA_VALIDATION_VALID_DIR ## validated report folder inside data validation folder\n",
    "\t\t)\n",
    "      self.invalid_dir_name:str=os.path.join(\n",
    "         self.data_validation_dir,traning_pipline.DATA_VALIDATION_INVALID_DIR ## invalid report folder inside data validation folder\n",
    "\t\t)\n",
    "      self.drift_report_dir:str=os.path.join(\n",
    "         self.data_validation_dir,traning_pipline.DATA_VALIDATION_DRIFT_REPORT_DIR,traning_pipline.DATA_VALIDATION_DRIFT_REPORT_FILE_NAME # data validation dir, drift report dir, report name\n",
    "\t\t)\n",
    "      self.valid_traning_data_store_path:str=os.path.join(\n",
    "         traning_pipline_config.artifact_dir, traning_pipline.DATA_INGESTION__DIR, traning_pipline.TRAIN_FILE_NAME  ## artifacts folder , ingest folder , train data path\n",
    "\t\t)\n",
    "      self.valid_test_data_store_path:str=os.path.join(\n",
    "         traning_pipline_config.artifact_dir,traning_pipline.DATA_INGESTION__DIR, traning_pipline.TEST_FILE_NAME ## artifacts folder , ingest folder , test data path\n",
    "\t\t)\n",
    "      self.invalid_traning_data_store_path:str=os.path.join(\n",
    "         traning_pipline_config.artifact_dir, traning_pipline.DATA_INGESTION__DIR, traning_pipline.TRAIN_FILE_NAME  ## artifacts folder , ingest folder , train data path\n",
    "\t\t)\n",
    "      self.invalid_test_data_store_path:str=os.path.join(\n",
    "         traning_pipline_config.artifact_dir,traning_pipline.DATA_INGESTION__DIR, traning_pipline.TEST_FILE_NAME ## artifacts folder , ingest folder , test data path\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components Output Artifacts Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class DataValidationArtifact:\n",
    "    validation_status:bool\n",
    "    valid_train_path:str\n",
    "    valid_test_path:str\n",
    "    invalid_train_path:str\n",
    "    invalid_test_path:str\n",
    "    drift_report_path:str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Validation Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'write_yaml_file' from 'networksecurity.utils.utills' (d:\\MLOPS\\NetWork Security\\networksecurity\\utils\\utills.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m List\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ks_2samp\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworksecurity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutills\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_yaml,write_yaml_file\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworksecurity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworksecurity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CustomException\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'write_yaml_file' from 'networksecurity.utils.utills' (d:\\MLOPS\\NetWork Security\\networksecurity\\utils\\utills.py)"
     ]
    }
   ],
   "source": [
    "from networksecurity.logging.logger import logging\n",
    "from networksecurity.exception.exception import CustomException\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "from scipy.stats import ks_2samp\n",
    "from networksecurity.utils.utills import read_yaml,write_yaml_file\n",
    "from networksecurity.logging.logger import logging\n",
    "from networksecurity.exception.exception import CustomException\n",
    "from networksecurity.entity.artifact_entity import DataIngestionArtifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValidation:\n",
    "    def __init__(self, training_pipeline_config: DataValidationConfig, data_ingestion_artifacts: DataIngestionArtifact) -> None:\n",
    "        self.data_ingestion_artifacts = data_ingestion_artifacts\n",
    "        self.data_validation_config = training_pipeline_config\n",
    "        schema_file_path = os.path.join(training_pipeline_config.SCHEMA_FILE_DIR, training_pipeline_config.SCHEMA_FILE_NAME)\n",
    "        self.schema_config = read_yaml(schema_file_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def read_data(filepath: str) -> pd.DataFrame:\n",
    "        try:\n",
    "            return pd.read_csv(filepath)\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def validate_num_of_cols(self, df: pd.DataFrame) -> bool:\n",
    "        try:\n",
    "            expected_num_of_cols = len(self.schema_config['columns'])\n",
    "            actual_num_of_cols = len(df.columns)\n",
    "            logging.info(f'Expected number of columns: {expected_num_of_cols}')\n",
    "            logging.info(f'Actual number of columns: {actual_num_of_cols}')\n",
    "\n",
    "            return expected_num_of_cols == actual_num_of_cols\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def detect_data_drift(self, base_df: pd.DataFrame, current_df: pd.DataFrame, threshold: float = 0.05) -> bool:\n",
    "        try:\n",
    "            status = True\n",
    "            report = {}\n",
    "\n",
    "            for col in base_df.columns:\n",
    "                base_data = base_df[col]\n",
    "                current_data = current_df[col]\n",
    "                drift_test = ks_2samp(data1=base_data, data2=current_data)\n",
    "                is_drifted = drift_test.pvalue < threshold\n",
    "                report[col] = {\n",
    "                    \"p_value\": float(drift_test.pvalue),\n",
    "                    \"drift_status\": is_drifted\n",
    "                }\n",
    "                if is_drifted:\n",
    "                    status = False\n",
    "\n",
    "            drift_report_path = self.data_validation_config.drift_report_dir\n",
    "            os.makedirs(os.path.dirname(drift_report_path), exist_ok=True)\n",
    "            write_yaml_file(file_path=drift_report_path, content=report)\n",
    "\n",
    "            logging.info('Data drift detection completed and report generated.')\n",
    "            return status\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n",
    "\n",
    "    def initiate_data_validation(self) -> DataValidationArtifact:\n",
    "        try:\n",
    "            train_file_path = self.data_ingestion_artifacts.trained_file_path\n",
    "            test_file_path = self.data_ingestion_artifacts.test_file_path\n",
    "\n",
    "            # Read training and test data\n",
    "            train_df = self.read_data(train_file_path)\n",
    "            test_df = self.read_data(test_file_path)\n",
    "            logging.info('Data read from training and test files completed.')\n",
    "\n",
    "            # Validate number of columns\n",
    "            if not self.validate_num_of_cols(df=train_df):\n",
    "                raise CustomException(\"Training data does not contain the expected columns.\", sys)\n",
    "            if not self.validate_num_of_cols(df=test_df):\n",
    "                raise CustomException(\"Testing data does not contain the expected columns.\", sys)\n",
    "\n",
    "            # Check for data drift\n",
    "            drift_status = self.detect_data_drift(base_df=train_df, current_df=test_df)\n",
    "\n",
    "            # Save validated data\n",
    "            os.makedirs(os.path.dirname(self.data_validation_config.valid_training_data_store_path), exist_ok=True)\n",
    "            train_df.to_csv(self.data_validation_config.valid_training_data_store_path, index=False, header=True)\n",
    "            test_df.to_csv(self.data_validation_config.valid_test_data_store_path, index=False, header=True)\n",
    "\n",
    "            # Create DataValidationArtifact\n",
    "            data_validation_artifact = DataValidationArtifact(\n",
    "                validation_status=drift_status,\n",
    "                valid_train_path=self.data_validation_config.valid_training_data_store_path,\n",
    "                valid_test_path=self.data_validation_config.valid_test_data_store_path,\n",
    "                invalid_train_path=None,\n",
    "                invalid_test_path=None,\n",
    "                drift_report_path=self.data_validation_config.drift_report_dir\n",
    "            )\n",
    "\n",
    "            logging.info('Data validation completed successfully.')\n",
    "            return data_validation_artifact\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networksecurity.components.data_ingestion import DataIngestion\n",
    "from networksecurity.entity.artifact_entity import DataIngestionArtifact\n",
    "from networksecurity.entity.config_entity import DataIngestionConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   having_IP_Address  URL_Length  Shortining_Service  having_At_Symbol  \\\n",
      "0                 -1           1                   1                 1   \n",
      "1                  1           1                   1                 1   \n",
      "2                  1           0                   1                 1   \n",
      "3                  1           0                   1                 1   \n",
      "4                  1           0                  -1                 1   \n",
      "\n",
      "   double_slash_redirecting  Prefix_Suffix  having_Sub_Domain  SSLfinal_State  \\\n",
      "0                        -1             -1                 -1              -1   \n",
      "1                         1             -1                  0               1   \n",
      "2                         1             -1                 -1              -1   \n",
      "3                         1             -1                 -1              -1   \n",
      "4                         1             -1                  1               1   \n",
      "\n",
      "   Domain_registeration_length  Favicon  ...  popUpWidnow  Iframe  \\\n",
      "0                           -1        1  ...            1       1   \n",
      "1                           -1        1  ...            1       1   \n",
      "2                           -1        1  ...            1       1   \n",
      "3                            1        1  ...            1       1   \n",
      "4                           -1        1  ...           -1       1   \n",
      "\n",
      "   age_of_domain  DNSRecord  web_traffic  Page_Rank  Google_Index  \\\n",
      "0             -1         -1           -1         -1             1   \n",
      "1             -1         -1            0         -1             1   \n",
      "2              1         -1            1         -1             1   \n",
      "3             -1         -1            1         -1             1   \n",
      "4             -1         -1            0         -1             1   \n",
      "\n",
      "   Links_pointing_to_page  Statistical_report  Result  \n",
      "0                       1                  -1      -1  \n",
      "1                       1                   1      -1  \n",
      "2                       0                  -1      -1  \n",
      "3                      -1                   1      -1  \n",
      "4                       1                   1       1  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    },
    {
     "ename": "CustomException",
     "evalue": "Error occurred python script name [C:\\Users\\www58\\AppData\\Local\\Temp\\ipykernel_23828\\2982643942.py] line number [8] error message [module 'networksecurity.constant.traning_pipline' has no attribute 'DATA_VALIDATION_DIR_NAME']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m data_ingestion_artifacts\u001b[38;5;241m=\u001b[39mdata_ingestion\u001b[38;5;241m.\u001b[39minitiate_data_ingestion()\n\u001b[1;32m----> 8\u001b[0m data_validation_config\u001b[38;5;241m=\u001b[39m\u001b[43mDataValidationConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraning_pipline_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraning_pipline_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m data_validation\u001b[38;5;241m=\u001b[39mDataValidation(training_pipeline_config\u001b[38;5;241m=\u001b[39mdata_validation_config,data_ingestion_artifacts\u001b[38;5;241m=\u001b[39mdata_ingestion_artifacts)\n",
      "Cell \u001b[1;32mIn[21], line 12\u001b[0m, in \u001b[0;36mDataValidationConfig.__init__\u001b[1;34m(self, traning_pipline_config)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,traning_pipline_config:TraningPiplineConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_validation_dir:\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m---> 12\u001b[0m       \ttraning_pipline_config\u001b[38;5;241m.\u001b[39martifact_dir,\u001b[43mtraning_pipline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATA_VALIDATION_DIR_NAME\u001b[49m \u001b[38;5;66;03m## crating data validaton folder inside artifacts\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \t\t)\n\u001b[0;32m     14\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_dir_name:\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     15\u001b[0m          \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_validation_dir, traning_pipline\u001b[38;5;241m.\u001b[39mDATA_VALIDATION_VALID_DIR \u001b[38;5;66;03m## validated report folder inside data validation folder\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \t\t)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'networksecurity.constant.traning_pipline' has no attribute 'DATA_VALIDATION_DIR_NAME'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mCustomException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m    data_ingestion\u001b[38;5;241m.\u001b[39minitiate_data_ingestion()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 12\u001b[0m            \u001b[38;5;28;01mraise\u001b[39;00m CustomException(e,sys)\n",
      "\u001b[1;31mCustomException\u001b[0m: Error occurred python script name [C:\\Users\\www58\\AppData\\Local\\Temp\\ipykernel_23828\\2982643942.py] line number [8] error message [module 'networksecurity.constant.traning_pipline' has no attribute 'DATA_VALIDATION_DIR_NAME']"
     ]
    }
   ],
   "source": [
    "try:\n",
    "   traning_pipline_config=TraningPiplineConfig()\n",
    "   data_ingestion_config=DataIngestion(data_ingestion_config=traning_pipline_config)\n",
    "   data_ingestion_config=DataIngestionConfig(traning_pipline_config=traning_pipline_config)\n",
    "   data_ingestion=DataIngestion(data_ingestion_config=data_ingestion_config)\n",
    "   data_ingestion_artifacts=data_ingestion.initiate_data_ingestion()\n",
    "   \n",
    "   data_validation_config=DataValidationConfig(traning_pipline_config=traning_pipline_config)\n",
    "   data_validation=DataValidation(training_pipeline_config=data_validation_config,data_ingestion_artifacts=data_ingestion_artifacts)\n",
    "   data_ingestion.initiate_data_ingestion()\n",
    "except Exception as e:\n",
    "           raise CustomException(e,sys)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
